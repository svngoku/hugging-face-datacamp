{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "389cda9f-d709-4cb7-9312-8bd262e31d47",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-03T22:26:52.226140Z",
     "iopub.status.busy": "2022-12-03T22:26:52.224858Z",
     "iopub.status.idle": "2022-12-03T22:27:02.889994Z",
     "shell.execute_reply": "2022-12-03T22:27:02.888242Z",
     "shell.execute_reply.started": "2022-12-03T22:26:52.226109Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.9/dist-packages (0.11.0)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile) (1.15.1)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (21.3)\n",
      "Collecting numba>=0.45.1\n",
      "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from librosa) (5.1.1)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa) (63.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.10)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23702 sha256=4c5d293f7e97224488825b0c0af7ef6b3fbcf76c1a586292aa30a5414471afdd\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/76/a4/cfb55573167a1f5bde7d7a348e95e509c64b2c3e8f921932c3\n",
      "Successfully built audioread\n",
      "Installing collected packages: appdirs, llvmlite, audioread, pooch, numba, resampy, librosa\n",
      "Successfully installed appdirs-1.4.4 audioread-3.0.0 librosa-0.9.2 llvmlite-0.39.1 numba-0.56.4 pooch-1.6.0 resampy-0.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install soundfile librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e01c8f-53f6-4e7b-bb4b-52a1be01af57",
   "metadata": {},
   "source": [
    "## Utilisation d'un pipeline\n",
    "Bien que chaque tâche ait un pipeline() associé, il est plus simple d'utiliser l'abstraction générale pipeline() qui contient tous les pipelines spécifiques à la tâche. \n",
    "Le `pipeline()` charge automatiquement un modèle par défaut et une classe de prétraitement capable d'inférer pour votre tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a431d-a176-4d6f-9281-2052cb5a83e4",
   "metadata": {},
   "source": [
    "### 1. Commencez par créer un `pipeline()` et spécifiez une tâche d'inférence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c1c12-7423-401a-8a9f-2ac87a3230d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:05:09.075651Z",
     "iopub.status.busy": "2022-12-03T22:05:09.075236Z",
     "iopub.status.idle": "2022-12-03T22:05:29.303164Z",
     "shell.execute_reply": "2022-12-03T22:05:29.302333Z",
     "shell.execute_reply.started": "2022-12-03T22:05:09.075624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab74befb77147809cbb506231d83e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b6c642c0624e1287cc2f33646c4db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d3208397714e558a3a63126736b396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc86c33f7b8e4151846a67a66cb0d1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cdc1e77b184f62bba7c0d17a46c963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Game of Thrones is a story about ichty women in the modern Western world.\\n\\n\\nWhat is it about these lovely ladies that have so much to offer? Where do they go to make ends meet? Who does the marriage in question have sex'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73717e-2cbe-45f4-9c0c-48d1bfe459f6",
   "metadata": {},
   "source": [
    "### 2. Passez votre texte d'entrée au `pipeline()` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16d310-3b6a-4393-91d5-124d11d9adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(\n",
    "    \"Game of Thrones is a story about \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32e2d53-5608-4089-a538-f647b8f2a8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:06:05.512461Z",
     "iopub.status.busy": "2022-12-03T22:06:05.511751Z",
     "iopub.status.idle": "2022-12-03T22:06:08.483617Z",
     "shell.execute_reply": "2022-12-03T22:06:08.482284Z",
     "shell.execute_reply.started": "2022-12-03T22:06:05.512430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, and Eight For the Undead, the Orcs in their city halls. These all have their own unique abilities. No power can keep'}],\n",
       " [{'generated_text': 'Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne upon The Way. The battle ended. For all eternity.\\n\\n\\nKirby played the roles of a lonely and frustrated young boy searching for his lost lover'}]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    [\n",
    "        \"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone\",\n",
    "        \"Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e06708-d9db-4067-8820-f277a54107e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:06:47.093685Z",
     "iopub.status.busy": "2022-12-03T22:06:47.093040Z",
     "iopub.status.idle": "2022-12-03T22:06:49.684528Z",
     "shell.execute_reply": "2022-12-03T22:06:49.683612Z",
     "shell.execute_reply.started": "2022-12-03T22:06:47.093634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Game of Thrones is a story about a woman \\xa0who finds herself trapped in a dangerous world. She's searching for her loved ones in a world that looks very like, well, the world of her father. In this new series, you'll\"},\n",
       " {'generated_text': 'Game of Thrones is a story about a woman \\xa0living an ordinary life in exile, where everything is okay. Everything is going as planned. There are rules. There are a lot of things that can mess things up. The main characters are characters'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    \"Game of Thrones is a story about a woman \",\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bbe0c-0ddd-4434-85e5-14d2ab73851e",
   "metadata": {},
   "source": [
    "## Choisir un model et un tokenizer\n",
    "Le `pipeline()` accepte n'importe quel modèle du Hub. Il existe des balises sur le Hub qui vous permettent de filtrer le modèle que vous souhaitez utiliser pour votre tâche. \n",
    "Une fois que vous avez choisi un modèle approprié, chargez-le avec la classe `AutoModelFor` et `AutoTokenizer` correspondante. \n",
    "Par exemple, chargez la classe `AutoModelForCausalLM` pour une tâche de modélisation du langage causal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1301858d-9c6d-40bc-8b17-af869cbfe0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:09:02.533878Z",
     "iopub.status.busy": "2022-12-03T22:09:02.533492Z",
     "iopub.status.idle": "2022-12-03T22:09:12.743700Z",
     "shell.execute_reply": "2022-12-03T22:09:12.742499Z",
     "shell.execute_reply.started": "2022-12-03T22:09:02.533852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b583eaa09846aea1c8ed16b8034c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b926a5d94b04c2aae5197fa748a8ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c2e1d9bfb94e9eb5e27f931f1e8c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fabb8de995f4356b51be9808fc99bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7c23e8812343b193a73bfdb96f6685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94934b40-f0c4-4a20-a578-c37f00f7a657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:09:33.363248Z",
     "iopub.status.busy": "2022-12-03T22:09:33.362864Z",
     "iopub.status.idle": "2022-12-03T22:09:33.386668Z",
     "shell.execute_reply": "2022-12-03T22:09:33.385697Z",
     "shell.execute_reply.started": "2022-12-03T22:09:33.363221Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7033ceb9-aeee-45f1-99d3-33cfea9a5517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:12:06.189400Z",
     "iopub.status.busy": "2022-12-03T22:12:06.187832Z",
     "iopub.status.idle": "2022-12-03T22:12:07.286507Z",
     "shell.execute_reply": "2022-12-03T22:12:07.285567Z",
     "shell.execute_reply.started": "2022-12-03T22:12:06.189366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'From the Ancient Kingdom Kongo in Africa, many warriors decide to ikage to help them. He is also the grandson of his grandfather, and was also a leader of the new Dynasty.\\n\\n\\n\\nHis name is Shigaei'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"From the Ancient Kingdom Kongo in Africa, many warriors decide to \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc47eb-39b9-4c36-b115-dcba9af457c0",
   "metadata": {},
   "source": [
    "## Audio Pipeline\n",
    "Le `pipeline()` prend également en charge des tâches audio telles que la classification audio et la reconnaissance automatique de la parole.\n",
    "\n",
    "Par exemple, classons l'émotion dans ce clip audio :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a28bd4-2e62-4d74-9544-71ae13441afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:27:11.337745Z",
     "iopub.status.busy": "2022-12-03T22:27:11.337202Z",
     "iopub.status.idle": "2022-12-03T22:27:12.943617Z",
     "shell.execute_reply": "2022-12-03T22:27:12.942293Z",
     "shell.execute_reply.started": "2022-12-03T22:27:11.337700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr_demo (/root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_demo/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "audio_file = ds[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c6d9b4-8353-4310-a6cc-2c1026648ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:23:27.001751Z",
     "iopub.status.busy": "2022-12-03T22:23:27.001393Z",
     "iopub.status.idle": "2022-12-03T22:23:55.003419Z",
     "shell.execute_reply": "2022-12-03T22:23:55.002253Z",
     "shell.execute_reply.started": "2022-12-03T22:23:27.001725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0648c4c847b34596a68dd011ee81f799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4666e6ddce64049a77bccbb69e8234b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.weight', 'classifier.dense.weight', 'classifier.output.bias', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.weight', 'projector.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00379d73774a51880cf44e0f44e99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_classifier = pipeline(\n",
    "    task=\"audio-classification\", model=\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15db90dc-3dc5-43bc-8b33-19ffd7725063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:27:25.516493Z",
     "iopub.status.busy": "2022-12-03T22:27:25.515254Z",
     "iopub.status.idle": "2022-12-03T22:27:27.616275Z",
     "shell.execute_reply": "2022-12-03T22:27:27.614847Z",
     "shell.execute_reply.started": "2022-12-03T22:27:25.516462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1315, 'label': 'calm'},\n",
       " {'score': 0.1307, 'label': 'neutral'},\n",
       " {'score': 0.1274, 'label': 'sad'},\n",
       " {'score': 0.1261, 'label': 'fearful'},\n",
       " {'score': 0.1242, 'label': 'happy'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = audio_classifier(audio_file)\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3970513-29b6-40e3-abe1-4d6697da585f",
   "metadata": {},
   "source": [
    "## Vision Pipeline\n",
    "L'utilisation d'un `pipeline()` pour les tâches de vision est pratiquement identique.\n",
    "Spécifiez votre tâche et passez votre image au classificateur.L'image peut être un lien ou un chemin local vers l'image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3a4325-b60a-485f-8a92-287a8941a18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:29:27.160142Z",
     "iopub.status.busy": "2022-12-03T22:29:27.159769Z",
     "iopub.status.idle": "2022-12-03T22:29:35.917415Z",
     "shell.execute_reply": "2022-12-03T22:29:35.915842Z",
     "shell.execute_reply.started": "2022-12-03T22:29:27.160142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 (https://huggingface.co/google/vit-base-patch16-224)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe7385962e24692890ddae0aa7c4b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135aad7a1d0d4443b52a7e6600a90a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fd1ca669bc4f8cb113fef3f62e3f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4335, 'label': 'lynx, catamount'},\n",
       " {'score': 0.0348,\n",
       "  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n",
       " {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'},\n",
       " {'score': 0.0239, 'label': 'Egyptian cat'},\n",
       " {'score': 0.0229, 'label': 'tiger cat'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_classifier = pipeline(task=\"image-classification\")\n",
    "preds = vision_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af664a97-f5fb-4a20-aea6-eab2e1256983",
   "metadata": {},
   "source": [
    "## Pipeline multimodal\n",
    "\n",
    "Le `pipeline()` prend en charge plus d'une modalité. Par exemple, une tâche de réponse à une question visuelle (VQA) combine texte et image. N'hésitez pas à utiliser le lien d'une image de votre choix et une question que vous souhaitez poser sur cette image. \n",
    "\n",
    "L'image peut être une URL ou un chemin d'accès local à l'image.\n",
    "\n",
    "Par exemple, si vous utilisez la même image que dans le pipeline de vision ci-dessus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e988a0a-640b-45da-8c1d-80f2bb431a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:35:58.652011Z",
     "iopub.status.busy": "2022-12-03T22:35:58.651622Z",
     "iopub.status.idle": "2022-12-03T22:35:58.656523Z",
     "shell.execute_reply": "2022-12-03T22:35:58.655441Z",
     "shell.execute_reply.started": "2022-12-03T22:35:58.651984Z"
    }
   },
   "outputs": [],
   "source": [
    "image = \"https://upload.wikimedia.org/wikipedia/commons/4/45/United_States_Air_Force_Boeing_VC-25_%2892-9000%29_landing_at_Dayton_International_Airport_%281%29.jpg\"\n",
    "question = \"What happend on this image  ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d781c39c-3458-4690-9a88-898ae0fd7825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T22:36:00.701295Z",
     "iopub.status.busy": "2022-12-03T22:36:00.700892Z",
     "iopub.status.idle": "2022-12-03T22:36:03.358929Z",
     "shell.execute_reply": "2022-12-03T22:36:03.357974Z",
     "shell.execute_reply.started": "2022-12-03T22:36:00.701278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3307, 'answer': 'nothing'},\n",
       " {'score': 0.1866, 'answer': 'plane'},\n",
       " {'score': 0.0978, 'answer': 'flying'},\n",
       " {'score': 0.0924, 'answer': 'airplane'},\n",
       " {'score': 0.0869, 'answer': 'fly'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa = pipeline(task=\"vqa\")\n",
    "preds = vqa(image=image, question=question)\n",
    "preds = [\n",
    "    {\"score\": round(pred[\"score\"], 4), \"answer\": pred[\"answer\"]} for pred in preds\n",
    "]\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
